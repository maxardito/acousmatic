<h2>Modeling Typomorphology using Group Representations</h2>

<p>
    Music theorist Brian Kane points out a number of similarities between Schaeffer's philosophy of sound
    and Husserl's phenomenology [Kan14]. This is a striking comparison in itself, because
    it warants an reinvestigation of Schaeffer's notion of the sound object by proxy of 
    Husserl's mathematical influences. For instance, Husserl’s method of examining the essence of
    objects by identifying their imagined invariant properties not only reflects
    Schaeffer's writings about the invariance of the sound object, but also reflects an important
    influence from contemporaneous shifts in mathematical thinking, particularly in the
    realm of geometric group theory. His use of the term invariance was not accidental,
    but rooted in his decision to align his formal ontology with mathematics. Influenced
    by Hilbert's axiomatization of Euclidean geometry, Cantor's set theory, and most
    notably Felix Klein’s Erlangen Programme, Husserl drew from the reorientation of
    geometry as the study of abstract structures, centered around the mathematical group.
    This shift, from viewing geometry as the study of physical space to understanding it
    as the science of possible forms, allowed for a move to the study of invariant
    structures under transformations. Figures like Cayley, Sylvester, Grassmann, Riemann,
    and others, whose work on algebraic invariants and geometric transformations laid the
    groundwork for this shift, also profoundly impacted Husserl’s own development of
    phenomenological invariance. According to [Rou23], Husserl was particularly influenced
    by two aspects of these geometric ideas: the epistemic transition from experienced to
    geometric shapes, and the understanding of geometric concepts through interaction with
    the physical world and imaginative variation. We can see this quite clearly in 
    Schaeffer's approach to the invariance of the sound object, which can be seen as
    analogous to Klein's and Husserl’s explorations of invariant properties, each
    methodology sharing a common historical and philosophical context. 
</p>
<p>
    Based on this connection, an argument could be made for the mathematical language of
    the Erlangen Programme to be integrated into the Schaefferian project---a
    reinterpretation of typomorphology with respect to the language of group
    representation theory. For instance, we often model sound as a rather opaque vector
    \(x \in \matbb{R}\) which is a representation that doesn't reveal much. Instead, we
    might talk about a space of sound objects on which a sound \(x\) exist. We make two
    important assumptions about the space: first that there are underlying symmetries as a
    result of a group \(\mathfrak{G}\) underlying the space, and that this group is a Lie
    group---a differentiable manifold---which we denote as a topology $\tau$. By then
    providing a group representation \(\mathcal{X}\) on the space, we can do things like
    define the existence of a Haar measure and a norm on the space. We can even call it a
    Hilbert space, by defining a map from the group to \(L^{2}\) space. 
</p>
<p>
    \(\mathcal{X}(\mathfrak{G}_{\tau}) = \lbrace{x : \mathfrak{G}_{\tau} \rightarrow
    L^{2}(\mathfrak{G}_{\tau})\rbrace}\)
</p>
<p>
    In this context, a number of canonical representations of sound fit in naturally.
    For instance, \(\mathcal{X}\) can be thought of as a time-frequency dictionary---a set
    of elementary functions \(\mathcal{X} = \lbrace{\chi_{u, \xi}\rbrace}_{u, \xi \in
    \Lambda}\) that form a group representation, treating \(u\) and \(\xi\) as time-frequency
    coordinates. We can then talk about the STFT as a representation of the
    Weyl-Heisenberg group \(\mathfrak{W}_{\tau}\). A sound \(x\) can then be analyzed by
    way of \(\mathfrak{W}_{\tau}\)'s group actions of translation and modulation: 
</p>
<p>
    \(\langle{x(t - \tau), \rho(\mathfrak{t})w\rangle} = \langle{x, \rho(\mathfrak{t - \tau})w\rangle}\)
    \(\langle{x(t)e^{i2\pi\tau t}, \rho(\mathfrak{m})w\rangle} = \langle{x,\rho(\mathfrak{m} - \tau))w\rangle}\)
</p>
<p>
    The key here is that the sound object is an abstract notion, akin to the abstraction
    of a "geometric object" in group theory. This ends up fititng quite nicely with many
    approaches to deep learning, given the advent of "geometric" deep learning. In other
    words, something like a CNN can be seen computationally as a ... however, it can also
    be seen as a Lie group... 
</p.
    (Scattering)

    which allows us to analyze the timbre of different sounds in an affine space. Note
    that these two representations bleed into time-scale. A mesostructural analysis of
    sound would... whereas a microstructural analysis of sound would... 

    Likewise, a paper by Higgins notes that group disentanglement is a key in
    understanding MLP systems from a more direct perspective. 

    (Peter Weyl)

    What, then, would something like DDSP look like using this approach?

    ...
</p>

<h2>The Disentanglement Hypothesis</h2>
<p>
    A large contribution of this work is thus the evaluation of disentanglement techniques
    in the context of a DDSP model's conditional parameters. The task here is to extract
    optimal microstructural control parameters from a dataset of sounds to effectively
    control and condition a Differentiable Digital Signal Processing (DDSP) model during
    training. These control parameters are restricted to the time-varying spectral audio
    descriptors laid out in \cite{Peeters2011}. By interpreting the problem from a
    group-theoretical perspective, a given microsound \(x \in
    \mathcal{X}(\mathfrak{W}_{\tau})\) is projected via an operator \(\Gamma\) into \(K\)
    approximately independent subspaces \(\bigoplus_{k=1}^{K}W_{k}(\mathfrak{A}_{\tau})\).
    This projection ensures that group actions are orthogonal, with each parameter
    \(\rho|_{W_{k}}(\mathfrak{g})\) acting only on its designated subspace \(W_{k}\),
    enabling disentanglement of control parameters as described by \cite{Higgins2018}.
    This process yields a latent space where each parameter controls distinct,
    perceptually independent aspects of the output.
</p>
<p>
    An initial implementation of \(\Gamma\) could use Principal Component Analysis
    (PCA) to extract control parameters that capture the most variance across the
    dataset. However, PCA focuses on microstructural differences between sounds,
    limiting its scope. A more effective approach involves incorporating
    mesostructural representations to maintain equivariance between the DDSP's
    control parameters and the resynthesis parameters at both the micro and
    mesoscales. This allows the model to generate an expressive latent morphology
    of sounds that remains invariant to larger timbral structures. In Schaefferian
    terms, this approach disentangles the sound’s morphology from its typology,
    offering a deeper, perceptually meaningful representation.
</p>
<p>
    The method focuses on identifying a small set of spectrotemporal control
    parameters most correlated with the features of a low-dimensional projection
    of the dataset’s Joint Time-Frequency Scattering (JTFS) representation, as
    implemented by \cite{Lostanlen2023}. Using the isomap algorithm, the
    dimensionality of the JTFS representation is reduced while preserving small
    Euclidean distances in feature space, ensuring that high-dimensional
    representations are mapped onto an orthogonal, low-dimensional space. This
    three-dimensional feature space correlates with perceived timbral similarity,
    as shown by \cite{Lostanlen2021}.
</p>
<p>
    The model demonstrates how microstructural control parameters at the time
    scale of an STFT window \(w_{T}\) correlate with mesostructural
    representations at the larger time scale of a low-pass scattering filter
    \(\phi_{T}\). This correlation implies that control parameters in the DDSP
    model exhibit a perceptual disentanglement due to the Euclidean distance of
    points in the JTFS domain, representing mesostructural perceptual distance
    \cite{Lostanlen2021}. Ultimately, the model provides an efficient framework
    for extracting and utilizing control parameters that represent both micro and
    mesostructural features of sound, making it ideal for a range of audio
    synthesis applications.
</p>
